{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 3134515,
          "sourceType": "datasetVersion",
          "datasetId": 1909705
        },
        {
          "sourceId": 5256696,
          "sourceType": "datasetVersion",
          "datasetId": 3041726
        },
        {
          "sourceId": 11525879,
          "sourceType": "datasetVersion",
          "datasetId": 7228619
        },
        {
          "sourceId": 352930,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 294418,
          "modelId": 315037
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "ALVS REAL IMAGE",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakjj/ai-vs-real/blob/main/ALVS_REAL_IMAGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "manjilkarki_deepfake_and_real_images_path = kagglehub.dataset_download('manjilkarki/deepfake-and-real-images')\n",
        "birdy654_cifake_real_and_ai_generated_synthetic_images_path = kagglehub.dataset_download('birdy654/cifake-real-and-ai-generated-synthetic-images')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "pVA4AM6HR6K4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Improved image loading with progress tracking\n",
        "def load_image_data(folder_path, label, target_size=(32, 32)):\n",
        "    images = []\n",
        "    labels = []\n",
        "    total_files = len(os.listdir(folder_path))\n",
        "    print(f\"Loading {total_files} images from {folder_path}...\")\n",
        "\n",
        "    for i, img_name in enumerate(os.listdir(folder_path)):\n",
        "        img_path = os.path.join(folder_path, img_name)\n",
        "        try:\n",
        "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "            img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "\n",
        "            # Print progress every 1000 images\n",
        "            if (i+1) % 1000 == 0 or (i+1) == total_files:\n",
        "                print(f\"Loaded {i+1}/{total_files} images\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:21:28.908527Z",
          "iopub.execute_input": "2025-04-23T09:21:28.909084Z",
          "iopub.status.idle": "2025-04-23T09:21:28.915256Z",
          "shell.execute_reply.started": "2025-04-23T09:21:28.909059Z",
          "shell.execute_reply": "2025-04-23T09:21:28.914491Z"
        },
        "id": "p47t_VcoR6K6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(model, learning_rate=1e-3, optimizer=\"adam\", batchsize=32,\n",
        "               noise_stddev=0.1, dropout_rate=0.5):\n",
        "    efficientnet = model\n",
        "\n",
        "    inputs = keras.Input(shape=(32, 32, 3))\n",
        "    x = keras.layers.GaussianNoise(noise_stddev)(inputs)\n",
        "    x = efficientnet(inputs, training=False)\n",
        "\n",
        "    # Feature extraction\n",
        "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = keras.layers.Dense(256, activation='relu')(x)\n",
        "    x = keras.layers.BatchNormalization()(x)  # Added BatchNorm\n",
        "    x = keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Additional dense layer\n",
        "    x = keras.layers.Dense(128, activation='relu')(x)\n",
        "    x = keras.layers.Dropout(dropout_rate/2)(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=learning_rate,\n",
        "        decay_steps=10000,\n",
        "        decay_rate=0.9)\n",
        "\n",
        "    # Optimizer selection\n",
        "    if optimizer.lower() == \"adam\":\n",
        "        opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "    else:\n",
        "        opt = keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss=keras.losses.BinaryCrossentropy(),\n",
        "        metrics=[\n",
        "            keras.metrics.BinaryAccuracy(),\n",
        "            keras.metrics.Precision(),\n",
        "            keras.metrics.Recall()\n",
        "        ])\n",
        "\n",
        "    # Early stopping callback\n",
        "    callbacks = [\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=5,\n",
        "            restore_best_weights=True)\n",
        "    ]\n",
        "\n",
        "    print('Training model...')\n",
        "    history = model.fit(\n",
        "        x=X_train,\n",
        "        y=y_train,\n",
        "        batch_size=batchsize,\n",
        "        epochs=10,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:21:28.916519Z",
          "iopub.execute_input": "2025-04-23T09:21:28.916749Z",
          "iopub.status.idle": "2025-04-23T09:21:28.934841Z",
          "shell.execute_reply.started": "2025-04-23T09:21:28.916726Z",
          "shell.execute_reply": "2025-04-23T09:21:28.934262Z"
        },
        "id": "PJN6o0nxR6K7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateModel(cnnModel):\n",
        "    print(\"\\nEvaluating model...\")\n",
        "    results = cnnModel.evaluate(X_val, y_val, verbose=0)\n",
        "    print(f\"Loss: {results[0]:.4f}\")\n",
        "    print(f\"Accuracy: {results[1]:.4f}\")\n",
        "    print(f\"Precision: {results[2]:.4f}\")\n",
        "    print(f\"Recall: {results[3]:.4f}\")\n",
        "\n",
        "    y_pred = cnnModel.predict(X_val, verbose=0)\n",
        "    y_pred_conv = np.argmax(y_pred, axis=1)\n",
        "    y_true = np.argmax(y_val, axis=1)\n",
        "\n",
        "    # Enhanced confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(confusion_matrix(y_true, y_pred_conv),\n",
        "                annot=True, fmt=\"d\",\n",
        "                cmap=\"Blues\",\n",
        "                xticklabels=[\"REAL\", \"FAKE\"],\n",
        "                yticklabels=[\"REAL\", \"FAKE\"],\n",
        "                annot_kws={\"size\": 16})\n",
        "    plt.xlabel(\"Predicted Label\", fontsize=14)\n",
        "    plt.ylabel(\"True Label\", fontsize=14)\n",
        "    plt.title(\"Confusion Matrix\", fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "    # Classification report with additional metrics\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred_conv, target_names=[\"REAL\", \"FAKE\"]))\n",
        "\n",
        "    # Calculate additional metrics\n",
        "    f1 = f1_score(y_true, y_pred_conv)\n",
        "    recall = recall_score(y_true, y_pred_conv)\n",
        "    precision = precision_score(y_true, y_pred_conv)\n",
        "\n",
        "    print(f\"\\nF1 Score: {f1:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:21:28.935621Z",
          "iopub.execute_input": "2025-04-23T09:21:28.936406Z",
          "iopub.status.idle": "2025-04-23T09:21:28.954333Z",
          "shell.execute_reply.started": "2025-04-23T09:21:28.936382Z",
          "shell.execute_reply": "2025-04-23T09:21:28.95379Z"
        },
        "id": "Rd7sLNeQR6K7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def make_plot(history):\n",
        "    metrics = ['loss', 'binary_accuracy', 'precision', 'recall']\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i, metric in enumerate(metrics):\n",
        "        plt.subplot(2, 2, i+1)\n",
        "\n",
        "        # Plot training metric\n",
        "        plt.plot(history.history[metric], label=f'Training {metric}')\n",
        "\n",
        "        # Plot validation metric if it exists\n",
        "        val_metric = f'val_{metric}'\n",
        "        if val_metric in history.history:\n",
        "            plt.plot(history.history[val_metric], label=f'Validation {metric}')\n",
        "\n",
        "        plt.title(metric.upper())\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel(metric)\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:21:28.955017Z",
          "iopub.execute_input": "2025-04-23T09:21:28.955261Z",
          "iopub.status.idle": "2025-04-23T09:21:28.973146Z",
          "shell.execute_reply.started": "2025-04-23T09:21:28.95524Z",
          "shell.execute_reply": "2025-04-23T09:21:28.972496Z"
        },
        "id": "8Gm3h0ujR6K8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, base_path='/kaggle/working'):\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(base_path, exist_ok=True)\n",
        "\n",
        "    # Save weights\n",
        "    weights_path = os.path.join(base_path, 'AI_IMAGE_DETECTOR.weights.h5')\n",
        "    model.save_weights(weights_path)\n",
        "\n",
        "    # Save full model\n",
        "    model_path = os.path.join(base_path, 'AI_IMAGE_DETECTOR_full_model.h5')\n",
        "    model.save(model_path)\n",
        "\n",
        "    # Save model architecture as JSON\n",
        "    json_path = os.path.join(base_path, 'model_architecture.json')\n",
        "    with open(json_path, 'w') as json_file:\n",
        "        json_file.write(model.to_json())\n",
        "\n",
        "    print(f\"✅ Model saved successfully to {base_path}\")\n",
        "    print(f\"- Weights: {weights_path}\")\n",
        "    print(f\"- Full model: {model_path}\")\n",
        "    print(f\"- Architecture: {json_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:21:28.974728Z",
          "iopub.execute_input": "2025-04-23T09:21:28.974898Z",
          "iopub.status.idle": "2025-04-23T09:21:28.992172Z",
          "shell.execute_reply.started": "2025-04-23T09:21:28.974884Z",
          "shell.execute_reply": "2025-04-23T09:21:28.99154Z"
        },
        "id": "lZWwQuIJR6K8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(model, image_dir, num_images=10):\n",
        "    image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir)[:num_images]]\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    for i, img_path in enumerate(image_paths):\n",
        "        # Load and preprocess image\n",
        "        img = image.load_img(img_path, target_size=(32, 32))\n",
        "        img_array = image.img_to_array(img) / 255.0\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        # Predict\n",
        "        pred = model.predict(img_array, verbose=0)[0]\n",
        "        pred_class = np.argmax(pred)\n",
        "        confidence = np.max(pred)\n",
        "\n",
        "        # Display\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Pred: {'FAKE' if pred_class == 0 else 'REAL'}\\nConf: {confidence:.2f}\",\n",
        "                 color='green' if pred_class == 1 else 'red')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print detailed predictions\n",
        "    print(\"\\nDetailed Predictions:\")\n",
        "    for i, img_path in enumerate(image_paths):\n",
        "        img = image.load_img(img_path, target_size=(32, 32))\n",
        "        img_array = image.img_to_array(img) / 255.0\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        pred = model.predict(img_array, verbose=0)[0]\n",
        "        print(f\"{os.path.basename(img_path)}: {pred} → Class: {np.argmax(pred)} ({'FAKE' if np.argmax(pred) == 0 else 'REAL'})\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:21:28.992867Z",
          "iopub.execute_input": "2025-04-23T09:21:28.993066Z",
          "iopub.status.idle": "2025-04-23T09:21:29.008778Z",
          "shell.execute_reply.started": "2025-04-23T09:21:28.993042Z",
          "shell.execute_reply": "2025-04-23T09:21:29.008154Z"
        },
        "id": "4Fvqc5UmR6K9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "import os\n",
        "import numpy as np\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Input, MaxPool2D, Conv2D, Flatten, InputLayer, Reshape, Conv2DTranspose, BatchNormalization\n",
        "# import kaggle\n",
        "import zipfile\n",
        "import torch\n",
        "import joblib\n",
        "import shap\n",
        "import dill"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:21:29.105618Z",
          "iopub.execute_input": "2025-04-23T09:21:29.106385Z",
          "iopub.status.idle": "2025-04-23T09:21:29.110604Z",
          "shell.execute_reply.started": "2025-04-23T09:21:29.106365Z",
          "shell.execute_reply": "2025-04-23T09:21:29.109908Z"
        },
        "id": "a67cKT0zR6K9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define Constants and Paths (UPDATE THESE)\n",
        "IMG_ROWS, IMG_COLS = 32, 32\n",
        "TRAIN_PATH = r'/kaggle/input/deepfake-and-real-images/Dataset/Train'\n",
        "TEST_PATH = r'/kaggle/input/deepfake-and-real-images/Dataset/Test'    # Replace with your path\n",
        "\n",
        "# 2. Load and Prepare Data"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:23:40.758296Z",
          "iopub.execute_input": "2025-04-23T09:23:40.758798Z",
          "iopub.status.idle": "2025-04-23T09:23:40.762469Z",
          "shell.execute_reply.started": "2025-04-23T09:23:40.758775Z",
          "shell.execute_reply": "2025-04-23T09:23:40.761644Z"
        },
        "id": "lpUWsUfGR6K-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Loading training data...\")\n",
        "real_images, real_labels = load_image_data(os.path.join(TRAIN_PATH, 'Real'), [0, 1])\n",
        "fake_images, fake_labels = load_image_data(os.path.join(TRAIN_PATH, 'Fake'), [1, 0])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:23:42.14743Z",
          "iopub.execute_input": "2025-04-23T09:23:42.148054Z",
          "iopub.status.idle": "2025-04-23T09:36:14.086441Z",
          "shell.execute_reply.started": "2025-04-23T09:23:42.148032Z",
          "shell.execute_reply": "2025-04-23T09:36:14.085823Z"
        },
        "id": "fqXOr2I-R6K-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Loading test data...\")\n",
        "test_real_images, test_real_labels = load_image_data(os.path.join(TEST_PATH, 'Real'), [0, 1])\n",
        "test_fake_images, test_fake_labels = load_image_data(os.path.join(TEST_PATH, 'Fake'), [1, 0])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:36:14.087558Z",
          "iopub.execute_input": "2025-04-23T09:36:14.087765Z",
          "iopub.status.idle": "2025-04-23T09:36:35.494381Z",
          "shell.execute_reply.started": "2025-04-23T09:36:14.08775Z",
          "shell.execute_reply": "2025-04-23T09:36:35.493615Z"
        },
        "id": "EcMttKmkR6K-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Combine and normalize data\n",
        "X_train = np.concatenate((real_images, fake_images)).astype('float32') / 255.0\n",
        "y_train = np.concatenate((real_labels, fake_labels))\n",
        "X_test = np.concatenate((test_real_images, test_fake_images)).astype('float32') / 255.0\n",
        "y_test = np.concatenate((test_real_labels, test_fake_labels))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:37:07.105281Z",
          "iopub.execute_input": "2025-04-23T09:37:07.106019Z",
          "iopub.status.idle": "2025-04-23T09:37:08.79215Z",
          "shell.execute_reply.started": "2025-04-23T09:37:07.105988Z",
          "shell.execute_reply": "2025-04-23T09:37:08.791423Z"
        },
        "id": "9-vv-MEjR6K_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train/validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:37:11.462359Z",
          "iopub.execute_input": "2025-04-23T09:37:11.463014Z",
          "iopub.status.idle": "2025-04-23T09:37:11.964407Z",
          "shell.execute_reply.started": "2025-04-23T09:37:11.462989Z",
          "shell.execute_reply": "2025-04-23T09:37:11.96363Z"
        },
        "id": "OjMa1pPfR6K_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Initialize Model\n",
        "base_model = keras.applications.EfficientNetB0(\n",
        "    include_top=False,\n",
        "    weights=None,\n",
        "    input_shape=(IMG_ROWS, IMG_COLS, 3)\n",
        ")\n",
        "base_model.load_weights('/kaggle/input/eff/tensorflow2/default/1/efficientnetb0_notop.h5')  # Replace with your weights path\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:37:14.0337Z",
          "iopub.execute_input": "2025-04-23T09:37:14.034456Z",
          "iopub.status.idle": "2025-04-23T09:37:15.211296Z",
          "shell.execute_reply.started": "2025-04-23T09:37:14.034425Z",
          "shell.execute_reply": "2025-04-23T09:37:15.210556Z"
        },
        "id": "0OS8fhY2R6K_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4. Train Model\n",
        "print(\"\\nTraining model...\")\n",
        "trained_model, training_history = make_model(\n",
        "    base_model,\n",
        "    learning_rate=1e-3,\n",
        "    optimizer=\"adam\",\n",
        "    batchsize=32,\n",
        "    noise_stddev=0.1,\n",
        "    dropout_rate=0.5\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:37:20.167188Z",
          "iopub.execute_input": "2025-04-23T09:37:20.167662Z",
          "iopub.status.idle": "2025-04-23T09:53:02.531986Z",
          "shell.execute_reply.started": "2025-04-23T09:37:20.167639Z",
          "shell.execute_reply": "2025-04-23T09:53:02.531142Z"
        },
        "id": "tE8o11cIR6K_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Evaluate Model\n",
        "print(\"\\nEvaluating model...\")\n",
        "evaluateModel(trained_model)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:53:22.14076Z",
          "iopub.execute_input": "2025-04-23T09:53:22.141288Z",
          "iopub.status.idle": "2025-04-23T09:53:39.110547Z",
          "shell.execute_reply.started": "2025-04-23T09:53:22.141265Z",
          "shell.execute_reply": "2025-04-23T09:53:39.109802Z"
        },
        "id": "kW28X582R6K_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 6. Visualize Training Progress\n",
        "make_plot(training_history)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:53:39.111751Z",
          "iopub.execute_input": "2025-04-23T09:53:39.112009Z",
          "iopub.status.idle": "2025-04-23T09:53:39.590832Z",
          "shell.execute_reply.started": "2025-04-23T09:53:39.111987Z",
          "shell.execute_reply": "2025-04-23T09:53:39.589927Z"
        },
        "id": "lalC3kSAR6K_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Demo Prediction (Optional)\n",
        "from tensorflow.keras.preprocessing import image\n",
        "demo_image_path = '/kaggle/input/deepfake-and-real-images/Dataset/Test/Real/real_100.jpg'  # Replace with your test image\n",
        "if os.path.exists(demo_image_path):\n",
        "    print(\"\\nRunning demo prediction...\")\n",
        "    img = image.load_img(demo_image_path, target_size=(32, 32))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    pred = trained_model.predict(img_array, verbose=0)[0]\n",
        "    pred_class = np.argmax(pred)\n",
        "    confidence = np.max(pred)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Pred: {'FAKE' if pred_class == 0 else 'REAL'}\\nConf: {confidence:.2f}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"\\nDemo image not found at {demo_image_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:54:02.43503Z",
          "iopub.execute_input": "2025-04-23T09:54:02.435609Z",
          "iopub.status.idle": "2025-04-23T09:54:05.359178Z",
          "shell.execute_reply.started": "2025-04-23T09:54:02.435585Z",
          "shell.execute_reply": "2025-04-23T09:54:05.358371Z"
        },
        "id": "nGyWOMSPR6K_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 8. Batch Prediction on Multiple Test Images\n",
        "def test_multiple_images(model, test_dir, num_images=5, target_size=(32, 32)):\n",
        "    \"\"\"\n",
        "    Test the model on multiple images from the test directory\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        test_dir: Path to test directory (should contain 'REAL' and 'FAKE' subfolders)\n",
        "        num_images: Number of images to test from each class\n",
        "        target_size: Size to resize images\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    for i, class_name in enumerate(['Real', 'Fake']):\n",
        "        class_dir = os.path.join(test_dir, class_name)\n",
        "\n",
        "        # Get first 'num_images' from the class directory\n",
        "        image_files = [f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.png'))][:num_images]\n",
        "\n",
        "        for j, img_file in enumerate(image_files):\n",
        "            img_path = os.path.join(class_dir, img_file)\n",
        "\n",
        "            # Load and preprocess image\n",
        "            img = image.load_img(img_path, target_size=target_size)\n",
        "            img_array = image.img_to_array(img) / 255.0\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "            # Make prediction\n",
        "            pred = model.predict(img_array, verbose=0)[0]\n",
        "            pred_class = np.argmax(pred)\n",
        "            confidence = np.max(pred)\n",
        "\n",
        "            # Plot results\n",
        "            plt_idx = i * num_images + j + 1\n",
        "            plt.subplot(2, num_images, plt_idx)\n",
        "            plt.imshow(img)\n",
        "            plt.title(f\"True: {class_name}\\nPred: {'FAKE' if pred_class == 0 else 'REAL'}\\nConf: {confidence:.2f}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Usage example\n",
        "TEST_PATH = '/kaggle/input/deepfake-and-real-images/Dataset/Test'\n",
        "if os.path.exists(TEST_PATH):\n",
        "    print(f\"\\nTesting model on sample images from {TEST_PATH}...\")\n",
        "    test_multiple_images(trained_model, TEST_PATH, num_images=5)\n",
        "else:\n",
        "    print(f\"\\nTest directory not found at {TEST_PATH}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:54:14.181661Z",
          "iopub.execute_input": "2025-04-23T09:54:14.181931Z",
          "iopub.status.idle": "2025-04-23T09:54:15.349101Z",
          "shell.execute_reply.started": "2025-04-23T09:54:14.181911Z",
          "shell.execute_reply": "2025-04-23T09:54:15.348474Z"
        },
        "id": "Kj7yd3l7R6K_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def test_multiple_images(model, test_dir, num_images=8, target_size=(32, 32)):\n",
        "    \"\"\"\n",
        "    Test the model on multiple images from the test directory\n",
        "\n",
        "    Args:\n",
        "        model: Trained model\n",
        "        test_dir: Path to test directory (should contain 'Real' and 'Fake' subfolders)\n",
        "        num_images: Number of images to test from each class\n",
        "        target_size: Size to resize images\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    class_map = {'REAL': 1, 'FAKE': 0}  # Map for label vs prediction\n",
        "\n",
        "    for i, class_name in enumerate(['REAL', 'FAKE']):\n",
        "        class_dir = os.path.join(test_dir, class_name)\n",
        "\n",
        "        # Get first 'num_images' from the class directory\n",
        "        image_files = [f for f in os.listdir(class_dir) if f.endswith(('.jpg', '.png'))][:num_images]\n",
        "\n",
        "        for j, img_file in enumerate(image_files):\n",
        "            img_path = os.path.join(class_dir, img_file)\n",
        "\n",
        "            # Load and preprocess image\n",
        "            img = image.load_img(img_path, target_size=target_size)\n",
        "            img_array = image.img_to_array(img) / 255.0\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "            # Make prediction\n",
        "            pred = model.predict(img_array, verbose=0)[0]\n",
        "            pred_class = np.argmax(pred)\n",
        "            confidence = np.max(pred)\n",
        "\n",
        "            # Accuracy Tracking\n",
        "            true_class = class_map[class_name]\n",
        "            total += 1\n",
        "            if pred_class == true_class:\n",
        "                correct += 1\n",
        "\n",
        "            # Plot results\n",
        "            plt_idx = i * num_images + j + 1\n",
        "            plt.subplot(2, num_images, plt_idx)\n",
        "            plt.imshow(img)\n",
        "            plt.title(f\"True: {class_name}\\nPred: {'REAL' if pred_class == 1 else 'FAKE'}\\nConf: {confidence:.2f}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "    # Print Accuracy\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    print(f\"\\n✅ Model Accuracy on Sample Test Set: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Usage example\n",
        "TEST_PATH = '/kaggle/input/personal/datset'\n",
        "\n",
        "if os.path.exists(TEST_PATH):\n",
        "    print(f\"\\nTesting model on sample images from {TEST_PATH}...\")\n",
        "    test_multiple_images(trained_model, TEST_PATH, num_images=5)\n",
        "else:\n",
        "    print(f\"\\n❌ Test directory not found at {TEST_PATH}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:55:37.170339Z",
          "iopub.execute_input": "2025-04-23T09:55:37.170634Z",
          "iopub.status.idle": "2025-04-23T09:55:38.619378Z",
          "shell.execute_reply.started": "2025-04-23T09:55:37.170613Z",
          "shell.execute_reply": "2025-04-23T09:55:38.618575Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "zU3QCRNCR6K_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model.save_weights('/kaggle/working/AI_IMAGE_DETECTOR(DEEP).weights.h5')\n",
        "\n",
        "# Save the full model (architecture + weights + optimizer)\n",
        "trained_model.save('/kaggle/working/AI_IMAGE_DETECTOR_full_model(DEEP).h5')\n",
        "\n",
        "print(\"✅ Weights and full model saved successfully.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T10:08:48.629561Z",
          "iopub.execute_input": "2025-04-23T10:08:48.630279Z",
          "iopub.status.idle": "2025-04-23T10:08:49.796478Z",
          "shell.execute_reply.started": "2025-04-23T10:08:48.630254Z",
          "shell.execute_reply": "2025-04-23T10:08:49.795837Z"
        },
        "id": "ZSAAx0dTR6LA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-23T09:55:49.263376Z",
          "iopub.execute_input": "2025-04-23T09:55:49.263643Z",
          "iopub.status.idle": "2025-04-23T09:56:10.972432Z",
          "shell.execute_reply.started": "2025-04-23T09:55:49.263624Z",
          "shell.execute_reply": "2025-04-23T09:56:10.971747Z"
        },
        "id": "rauj0rPSR6LA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "0GED4RzdR6LA"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}